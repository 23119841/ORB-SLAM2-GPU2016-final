{
  "name": "ORB-SLAM2 GPU optimization",
  "tagline": "GPGPU 2016 Final Project",
  "body": "\r\n# Video\r\n[![Project Proposal](http://img.youtube.com/vi/Sngog64Y0pw/0.jpg)](https://www.youtube.com/watch?v=Sngog64Y0pw)\r\n[![Project Demo](http://img.youtube.com/vi/p77hLLRfBGQ/0.jpg)](https://www.youtube.com/watch?v=p77hLLRfBGQ)\r\n\r\n# Slides\r\n[slides](slides/index.html)\r\n\r\n# Abstract\r\nEnable GPU optimizations to achieve real time SLAM on the Jetson TX1 embedded computer. [ORB\\_SLAM2](https://github.com/raulmur/ORB_SLAM2)\r\n\r\n# Optimization details\r\n\r\n### Switch from OpenCV 2.4 to OpenCV 3.1\r\nOpenCV 3.1 introduces several features helpful to this project: custom memory allocator, \r\nCuda stream and rewrite of some essential algorithms, such as Fast and ORB.\r\nThese features allow us to fully exploit more Cuda APIs, such as Unified Memory.\r\n\r\n### Feature extraction reimplemented\r\nThere are several execution hotspots in the original `ORB_SLAM2`, including but not limited to\r\nprocedures like `FAST corner detection`, `Gaussian filter` and `ORB feature extraction`.\r\nFor example, in their `ORB feature extraction` implementation, an image is divided into many small tiles\r\nand `FAST` is invoked on each tile one or two times in order to achieve high accuracy.\r\nThe algorithm was effective yet inefficient.\r\nHence we implemented a slightly modified version of it in CUDA and parallelized the work\r\nof each tile.\r\n\r\n`ORB feature extraction` is also a costly but parallelizable procedure, so it's implemented with CUDA, too.\r\n\r\n### Overlap CPU and GPU execution\r\nHowever, there are still some irregular code segments that cannot be parallelized. So our next goal is to \r\nmaximize CPU/GPU overlap. Ideally if a CPU work is completed before a GPU kernel ends, then\r\nthe CPU work would be considered \"free\"; unfortunately, many CPU work have data dependencies on other GPU results,\r\nthus CPU/GPU work scheduling must be done wisely.\r\nWith the help of many profilings (thanks to NVVP), we've figured out a pretty good scheduling scheme\r\nto pipeline CPU and GPU work, such that GPU is kept as busy as possible while CPU can overlap many\r\nof it's execution with GPU.\r\n\r\n![Execution timeline](img/timeline.png)\r\n\r\nThe purple bars on the row \"Default domain\" indicates CPU work and the \"Compute\" row indicates GPU work.\r\n\r\n### Results\r\nFollowing are some charts of the speedups we achieved on an ordinary PC and on a Jetson TX1.\r\nThe PC's CPU/GPU is Xeon E3 1231 / GTX 760.\r\nThe statistics were mesured using chosen sequences of the KITTI dataset and live captured images from the \r\ncamera module on top of TX1.\r\n\r\nAfter enabling GPU optimization, the fps of live camera tracking is increased from 5.98 to 14.42 and frame \r\nprocessing time is reduced from 0.166s to 0.068s !\r\n\r\n![Mean tracking time per frame (lower is better)](img/mean_track_time.png)\r\n![Mean and peak fps (fps = 1 / (tracking + camera capture time))](img/FPS.png)\r\n![Speedups](img/speedups.png)\r\n\r\n### Contacts\r\n- B03902035 黃兆緯 <b03902035@ntu.edu.tw>\r\n- B03902074 陳耘志 <b03902074@ntu.edu.tw>\r\n- B03902082 江懿友 <b03902082@ntu.edu.tw>",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}